---
title: "FourVenues Scraper"
author: "Laura Martinez & Ana Pérez"
date: "2024-03-13"
output: html_document
runtime: shiny
---

```{=html}
<style>
body {
text-align: justify}
</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, knitr.purl.inline = TRUE)
```

## Fourvenues page scraper

This project was born from the motivation of helping other youngsters that might be doubtful of which one can be their best option for partying in Madrid, and since there is a webpage ([Fourvenues](https://www.fourvenues.com/es/discotecas-madrid)) that concentrates the sale of tickets of the majority of events and clubs in Madrid, we thought it was the best option for getting our data.

Thus our scraper will be on the page of Forvenues in which every day new events come up allowing people to buy tickets through their webpage. The web has a main page that displays all the options with different dates and times and once you enter into each event types of tickets come up, allowing the user to choose the entry that best suits their interests.

Without further ado, the process of explaining this page will be displayed below.

## Loading the necessary libraries

```{r}
# Load the RSelenium library
library(RSelenium)

#Load the API libraries
library(googleway)
library(jsonlite)
library(dotenv)

# Other libraries
library(devtools)
library(dplyr)
library(ggplot2)
library(httr)
library(leaflet)
library(lubridate)
library(magrittr)
library(OpenStreetMap)
library(plotly)
library(readr)
library(readxl)
library(rvest)
library(sf)
library(shiny)
library(stringr)
library(tibble)
library(tidyr)
library(vistime)
library(viridis)
library(writexl)
library(xml2)
```

#### Don´t forget to set your working directory

```{r}
#setwd("~")
```

## Start selenium

Now we are ready to start RSelenium, although beforehand it is necessary to install Mozzilla Firefox (as it is the browser this scraper will use) and follow a tutorial to install Java and Selenium on your computer.

Then, once that´s done, we can run this code:

```{r, eval=FALSE}
# Start the Selenium server with a different port
remDr <- rsDriver(port = 4586L, browser = "firefox")
```

Remember to change the number of the port every time you initialize RSelenium. And also note:

**BEWARE**: [At this point adjust the page that has just been opened (Firefox) to be as long as it can be in your screen]{.underline}

#### Set your user-agent (check yours [here](https://www.google.com/search?client=ubuntu&channel=fs&q=what%27s+my+user+agent&ie=utf-8&oe=utf-8))

Now, just in case we can set our user-agent so that the page recognises us as the ones downloading the data

```{r, eval=FALSE}
set_config(
  user_agent("Mozilla/5.0 ....)
)
```

#### Create a robust url

At this point, before reading the page we wanted to create a robust url for the page that works any time the scraper is run, so that it can always work regardless of the date in which this code is executed:

```{r, eval=FALSE}
# actual date
actual_date <- Sys.Date()
actual_date #We will use the actual date to modify the url

# Extract year and month from the actual_date variable
year <- substr(actual_date, 1, 4)
month <- as.integer(substr(actual_date, 6, 7))


#Use this function to transform the date extracted from the forvenues page
updated_url <- function(year, month) {
  # Convert month to two digits format (e.g., 1 -> 01, 10 -> 10)
  month_str <- sprintf("%02d", month)
  
  # Construct the URL
  forvenues_url <- paste0("https://www.fourvenues.com/es/discotecas-madrid/events?date=", year, "-", month_str)
  
  return(forvenues_url)
}


# Call the function to get the URL
forvenues_url <- updated_url(year, month)

forvenues_url # final URL
```

#### Navigate to the page and read it

Now, we are ready to navigate to the web page:

```{r, eval=FALSE}
# Navigate to the webpage
remDr$client$navigate(forvenues_url)
Sys.sleep(2)
```

**BEWARE - VERY IMPORTANT**: [Here accept the cookies so they don´t obstruct Selenium´s view of the events]{.underline}

Then, we can read the page:

```{r, eval=FALSE}
# Read the forvenues page
forvenues <- read_html(forvenues_url)
```

## Start selecting the info of the main page

After the previous steps are completed, we can now select and start cleaning at the same time the info of the Fourvenues page that we want to extract:

```{r, eval=FALSE}
# Get the names of each event (valid for any month)
forvenues |>  
  xml_find_all("//p[@class='mt-1 sm:mt-3 font-semibold text-xl sm:text-2xl text-black dark:text-white sm:w-full sm:text-clip']") |> 
  xml_text()
events <- forvenues |> 
  xml_find_all("(//div[@class='flex-grow relative p-3']//p)") |>
  xml_text()
events <- gsub(".*>(.*)<.*", "\\1", events)
events <- trimws(gsub("\\\\n", "", events))
renamed_events <- events
renamed_events #names of each event displayed

# Get the date of each event
date <- forvenues |>
  xml_find_all("(//div[@class='subtitle badge rounded text-xs sm:text-sm bg-secondary text-white p-1 sm:px-2']//h2)")
date <- gsub("<.*?>", "", date)
date <- gsub("\\s+", " ", date)
date

## transform the date with the following functions to dd-mm-yyyy
month_to_number <- function(month) {
  months <- c("Ene.", "Feb.", "Mar.", "Abr.", "May.", "Jun.", "Jul.", "Ago.", "Sep.", "Oct.", "Nov.", "Dic.")
  month_index <- match(month, months)
  return(sprintf("%02d", month_index))
}

## Function to convert your date format to desired format
convert_date_format <- function(date_str) {
  parts <- strsplit(trimws(date_str), " ")[[1]]
  day <- sprintf("%02d", as.numeric(gsub("\\D", "", parts[2])))
  month <- month_to_number(parts[3])
  year <- as.numeric(format(Sys.Date(), "%Y"))
  return(paste(day, month, year, sep = "-"))
}

## Apply the function to each date in the list
formatted_dates <- sapply(date, convert_date_format)
extracted_dates <- gsub('.*?"(.*?)"', "\\1", formatted_dates)

## Convert extracted dates to a list
dates_list <- strsplit(extracted_dates, '" "')

first_elements <- sapply(dates_list, function(x) x[1])
first_elements <- first_elements[first_elements != ""]

## Remove duplicates
unique_elements <- unique(first_elements)

repeated_dates <- rep(unique_elements, times = table(first_elements))
repeated_dates



# Get the hours of each event
hours <- forvenues |>
  xml_find_all("(//div[@class='subtitle text-xs sm:text-sm'])")

## start hour
start_h <- gsub(".*>(.*?)<.*>(.*?)<.*", "\\1", hours)
start_h <- trimws(gsub("\\\\n", "", start_h))
## end hour
end_h <- gsub(".*<i.*?>.*?</i>(.*?)\\s*</div>.*", "\\1", hours)


# Extract club name/location
club <- forvenues |>
  xml_find_all("(//div[@class='mt-1 badge rounded text-xs sm:text-sm bg-blue-200/30 dark:bg-blue-700/30 text-blue-600 dark:text-blue-100/50 p-1 px-2 whitespace-nowrap'])")
club <- gsub(".*<i.*?>(.*?)\\s*</i>(.*?)\\s*</div>.*", "\\2", club)

```

## Clicking on each event

Once the desired information of the main page has been stored in variables we will set our driver to make the clicks on each event later in the loop:

```{r, eval=FALSE}
# To make the clicks
driver <- remDr$client
```

## Defining our csv

Also we want to set our csv in which we want our scraped data to be stored. This csv should be in comma-separated-values format and should contain the same variables as the ones defined later in our tibble located inside the loop:

```{r, eval=FALSE}
# Remember to change the file path to your own´s
discotecas <- read_csv2("/.../discotecas_data_harvesting.csv", col_types = cols(start_time = "c", end_time = "c"))

```

## Ready for the Loop!

Now that we have the info on the main page stored in variables we can run the loop that will get the data of each event from the main page and then click on every single one of them and retrieve further specific data on each event.

We have set a sample of 200 events (note [1:200]) which can be removed in case all the events of the page are wanted.

Also! Remember to change the path of the csv again to your own´s in which you have the discotecas csv.

```{r, eval=FALSE}
# We start here the Loop
for (event_index in seq_along(renamed_events)[1:200]) { #We limit it to 200 events but this can be changed/removed
  print(event_index)
  event_name <- renamed_events[event_index]
  print(event_name)
  date <- repeated_dates[event_index]
  start_time <- start_h[event_index]
  end_time <- end_h[event_index]
  club_name <- club[event_index]
  
  
  Sys.sleep(3)
  
  #The path for each event is constructed with the name of the event and the date to avoid repeated results
  event_xpath <- paste0("//div[contains(@onclick, '", event_name, "') and contains(@onclick, '", date, "')]")
  
  Sys.sleep(4)
  
  #We tell Selenium to click over the event
  driver$findElement(value = event_xpath)$clickElement()
  
  Sys.sleep(3)
  
  #scroll down inside the event page
  event_webElem <- driver$findElement("css", "body")
  event_webElem$sendKeysToElement(list(key = "down_arrow"))
  event_webElem$sendKeysToElement(list(key = "down_arrow"))
  event_webElem$sendKeysToElement(list(key = "down_arrow"))
  event_webElem$sendKeysToElement(list(key = "down_arrow"))
  
  Sys.sleep(3)
  
  #Save the page source to extract the info below
  event_page_source <- driver$getPageSource()[[1]]
  event_page <- read_html(event_page_source)
  
  Sys.sleep(3)
  
  # Extract the entry name - (extracts both entries and guest lists)
  entry_name <-
    event_page %>%
    xml_find_all("//div[@class='relative p-3 mt-6 -mx-3
  bg-opacity-10 sm:rounded  ']//div[@class='text-lg text-primary dark:text-white font-semibold']") %>%
    xml_text()
  entry_name <- gsub(".*>(.*?)<.*", "\\1", entry_name)
  entry_name <- trimws(gsub("\\n", "", entry_name))
  
  Sys.sleep(2)
  
  # Extract the entry price - (extracts prices for both entries and guest lists)
  price <- event_page |>
    xml_find_all("//div[@class='relative p-3 mt-6 -mx-3
  bg-opacity-10 sm:rounded  ']//div[@class='font-semibold text-lg text-primary dark:text-white whitespace-nowrap px-3']")
  price <- gsub(".*>(.*?)<.*", "\\1", price)
  price <- trimws(gsub("\\n", "", price))
  
  Sys.sleep(2)
  
  # Scrape date from the event (in a different format)
  full_date <- event_page |>
    xml_find_all("(//h2[@class='pb-2 subtitle text-secondary dark:text-white text-sm sm:text-lg'])")
  full_date <- gsub("\\n", "", full_date)
  full_date <- gsub(".*>(.*?)<.*", "\\1", full_date)
  full_date <- trimws(gsub("\\n", "", full_date))
  full_date <- rep(full_date, each = length(entry_name))
  
  Sys.sleep(2)
  
  #Scrape the dress code of each event
  dress_code <- event_page %>%
    xml_find_all("//div[@class='mt-1 badge rounded text-sm bg-gray-100 dark:bg-gray-700 text-gray-600 dark:text-gray-400 p-1 px-2 bg-opacity-50 dark:bg-opacity-50 mb-1' and i[contains(@class, 'far fa-tshirt pr-1')]]")
  dress_code <- gsub('.*</i>\\s*([^<]+)\\s*</div>.*', '\\1', dress_code, perl = TRUE)
  dress_code <- sub('.*\\n(\\S.*)', '\\1', dress_code)
  dress_code <- trimws(dress_code)
  dress_code <- rep(dress_code, each = length(entry_name))
  
  Sys.sleep(2)
  
  # Extract the address of the event
  full_address <- event_page |>
    xml_find_all("(//div[@class='text-gray-600 dark:text-gray-400']//p)")
  
  name <- gsub('<p class="font-semibold">(.*?)</p>.*', "\\1", full_address)[1]
  name <- rep(name, each = length(entry_name))
  
  address <- gsub("<p>(.*?)</p>.*", "\\1", full_address)[2]
  address <- rep(address, each = length(entry_name))
  
  Sys.sleep(2)
  
  # Extract the google maps address
  coordinates <- event_page |>
    xml_find_all("(//div[@class='text-gray-600 dark:text-gray-400']//div)")
  
  coordinates <- gsub(".*query=(.*?)%2C(.*?);.*", "\\1, \\2", coordinates)
  coordinates
  
  latitude <- numeric(length(coordinates))
  longitude <- numeric(length(coordinates))
  
  # Loop through each coordinate string and extract latitude and longitude
  for (i in seq_along(coordinates)) {
    match <- gsub(".*?([0-9.-]+), ([0-9.-]+).*", "\\1", coordinates[i])
    latitude[i] <- as.numeric(match)
    
    match <- gsub(".*?([0-9.-]+), ([0-9.-]+).*", "\\2", coordinates[i])
    longitude[i] <- as.numeric(match)
  }
  
  # Keep only the first latitude and longitude
  latitude <- rep(latitude[1], each = length(entry_name))
  longitude <- rep(longitude[1], each = length(entry_name))
  
  Sys.sleep(2)
  
  
  # create a tibble with all the previous information
  event_tibble <- tibble(
    # poner nombre de variables en vez de nombre
    event_name = rep(event_name, each = length(entry_name)),
    date = rep(date, each = length(entry_name)),
    start_time = as.character(rep(start_time, each = length(entry_name))),
    end_time = rep(end_time, each = length(entry_name)),
    club_name = rep(club_name, each = length(entry_name)),
    entry_name = entry_name,
    entry_price = price,
    full_date = full_date,
    place = name,
    dress_code = dress_code,
    address = address,
    lat = latitude,
    lon = longitude
  )
  
  #Check the created tibble of each event and then keep on adding rows
  print(event_tibble)
  
  #Add each new event to the tibble discotecas with the rest of events
  discotecas <- rbind(discotecas, event_tibble)
  #Add each new event to the csv discotecas with the rest of events
  write_csv(discotecas, "/Users/.../discotecas_data_harvesting.csv")
  
  
  # go back
  driver$goBack()
  Sys.sleep(3)
  
  driver$executeScript("window.scrollBy(0, 900)") 
  
  # Scroll down on the main page
  webElem <- driver$findElement("css", "body")
  webElem$sendKeysToElement(list(key = "down_arrow"))
  webElem$sendKeysToElement(list(key = "down_arrow"))
  webElem$sendKeysToElement(list(key = "down_arrow"))
  webElem$sendKeysToElement(list(key = "down_arrow"))
  webElem$sendKeysToElement(list(key = "down_arrow"))
  webElem$sendKeysToElement(list(key = "down_arrow"))
  webElem$sendKeysToElement(list(key = "down_arrow"))
  webElem$sendKeysToElement(list(key = "down_arrow"))
  webElem$sendKeysToElement(list(key = "down_arrow"))
  webElem$sendKeysToElement(list(key = "down_arrow"))
}
```

Empty results are probably because tickets are not available yet or because the only available option are "mesas reservadas"

## Visualise and save the final data

```{r, eval=FALSE}
#visualise the final tibble
view(discotecas)

#Set your working directory to save the final results
setwd("~/Desktop/.../Final")

write_csv(discotecas, "discotecas_tibble.csv") #saved in a new csv (although we already have one)

write_xlsx(discotecas, "discotecas_tibble.xlsx") #saved in an xlsx to keep special characters 
```

And running this final chunk, the scraping of the Fourvenues page should be finished!

## Recoding of variables

In order to make the visualizations we intend to create, a bit of data processing should be done:

First, we import the shapefile available in the repository and our xlsx resulting from the scraping and we convert the later into a tibble to take care of the format of some of the variables such as "date".

```{r, eval=FALSE}
districts <- st_read("Distritos.shp") #read shapefile

districts <- districts |> 
  select(NOMBRE, geometry) |> 
  rename(district_name = NOMBRE) #adjust/rename some variables

districts <- st_transform(districts, 4326) #transform the coordinates system

discotecas <- read_excel("discotecas_tibble1.xlsx") #read the xlsx

discotecas <- as_tibble(discotecas) #convert it into a tibble
```

Also, before we put together the two previous datasets we need to change the format of the date to date format:

```{r, eval=FALSE}
discotecas$date <- as.Date(discotecas$date, format = "%d-%m-%Y") #modify the date format for future visualizations
```

Merge the data to add later the district variable to the discotecas dataset:

```{r, eval=FALSE}
discotecas_sf <- st_as_sf(discotecas, coords = c("lon", "lat"), crs = 4326)
merged_data <- st_join(discotecas_sf, districts, join = st_within)
discotecas_sf <- NULL
```

Now merge just the districts to our discotecas dataset:

```{r, eval=FALSE}
merged_data_unique <- merged_data |>  
  distinct(address, .keep_all = TRUE)

discotecas <- left_join(discotecas, 
                               select(merged_data_unique, 
                                      address, 
                                      district_name), 
                               by = "address")
```

#### Further cleaning of the data and creation of new variables

In the following chunks our data from the scraper will be further cleaned and modified and the variables for "entry price", "free entry", "price average" and "price range" will be created:

```{r, eval=FALSE}
#Replace names of Discotecas that are outside the center of Madrid
discotecas <- discotecas |> 
  mutate(district_name = if_else(is.na(district_name), "Afueras", district_name))

#Clean the entry_price variable
discotecas <- discotecas %>% 
  mutate(entry_price = as.numeric(str_replace(entry_price, "€", "")),
         entry_price = ifelse(is.na(entry_price), 0, entry_price))

#Create a free variable: 
discotecas <- discotecas |> 
  mutate(free = if_else(entry_price == "Gratis" | entry_price == "0", TRUE, FALSE))
```

Now let´s also create a price range and a price average:

```{r, eval=FALSE}
# Filter out entries with entry_price of 0
filtered_data <- discotecas |> 
  filter(entry_price != 0)

# Calculate price range for each club
price_ranges <- filtered_data |> 
  group_by(place) |> 
  summarise(min_price = min(entry_price),
            max_price = max(entry_price))

# Create a new variable for price range
discotecas <- left_join(discotecas, price_ranges, by = "place")

# Create price_range variable
discotecas$price_range <- ifelse(is.na(discotecas$min_price), NA, paste0(discotecas$min_price, "-", discotecas$max_price))

# Remove unnecessary columns
discotecas <- discotecas |> 
  select(-min_price, -max_price)


#Create the average price

discotecas <- discotecas %>%
  mutate(avg_price = ifelse(entry_price != 0, entry_price, NA)) %>%
  group_by(event_name) %>%
  mutate(avg_price = mean(avg_price, na.rm = TRUE)) %>%
  ungroup() %>%
  relocate(avg_price, .after = place)

discotecas$avg_price<- gsub("\\..*", "", discotecas$avg_price)
discotecas$avg_price <- as.numeric(discotecas$avg_price)
```

## Google Maps API

The objective of this section is to gather additional information about each club using the Google Maps API. More concretely, we aim to retrieve details such as the rating, the number of reviews, and the typology of each place. The ultimate goal is to visualize these places in a map using these variables.

We noticed that the denomination of certain places in our dataframe did not exactly match the one recognized by the Google Maps API. Consequently, the API couldn't identify these places, resulting in missing values. To address this issue, we decided to adjust the names (within the "place" column) in our dataset to ensure that all places were correctly identified, thereby reducing the amount of missing values.

### Recoding of 'place' column

```{r, eval=FALSE}
discotecas$place <- as.character(discotecas$place)
discotecas$place <- trimws(discotecas$place)

discotecas$place[discotecas$place == "La Reserva"] <- "La Reserva Club"
discotecas$place[discotecas$place == "Nazca Club"] <- "Sala Nazca Madrid"
discotecas$place[discotecas$place == "Copernico"] <- "Copérnico The Club"
discotecas$place[discotecas$place == "Dos passos"] <- "Restaurante Dos Passos"
discotecas$place[discotecas$place == "THE BASSEMENT"] <- "The Bassement Club"
discotecas$place[discotecas$place == "Av.Felipe II, 16, Goya Madrid"] <- "Vyta Club"
discotecas$place[discotecas$place == "Posh Club"] <- "Posh Madrid"
discotecas$place[discotecas$place == "EPOKA"] <- "Epoka the club"
discotecas$place[discotecas$place == "LA SOSPECHOSA"] <- "La Sospechosa Club"
discotecas$place[discotecas$place == "Posh Club"] <- "Posh Club"
discotecas$place[discotecas$place == "Marieta"] <- "Marieta Brunch"
discotecas$place[discotecas$place == "Meneo"] <- "Meneo Ponzano"
discotecas$place[discotecas$place == "BaoBao"] <- "BaoBao Madrid Discoteca"
discotecas$place[discotecas$place == "Kumarah"] <- "Kumarah Club"
discotecas$place[discotecas$place == "Goose"] <- "Changó Club (Peral´s temple)"
discotecas$place[discotecas$place == "SNOZONE XANADU"] <- "Jowke Club"
discotecas$place[discotecas$place == "VANITY"] <- "Vanity madrid"
discotecas$place[discotecas$place == "SLVJ"] <- "SLVJ Madrid Velazquez"
discotecas$place[discotecas$place == "Bardot"] <- "Bardot Madrid"
discotecas$place[discotecas$place == "Panda"] <- "Panda Club Madrid"
discotecas$place[discotecas$place == "MAU MAU"] <- "MAU MAU CLUB"
discotecas$place[discotecas$place == "Bonded"] <- "BONDED CLUB"
discotecas$place[discotecas$place == "Wonder"] <- "Wonder Studio Madrid"
discotecas$place[discotecas$place == "LIBERATA"] <- "Liberata Madrid"
discotecas$place[discotecas$place == "Bendito"] <- "Bendito Madrid"
discotecas$place[discotecas$place == "Vandido"] <- "VANDIDO Madrid"
discotecas$place[discotecas$place == "Sala Mon"] <- "Mon Madrid"
discotecas$place[discotecas$place == "Fitz Club"] <- "Fitz Club Madrid"
```

### Connecting to the API

The Google Maps API is a set of tools and services provided by Google that allows developers to integrate various mapping functionalities into their applications and websites. These functionalities include displaying maps, obtaining geographic data, calculating directions and distances, searching for place details, and much more. Here, you can find a step-by-step guide to set your own Google Maps API and replicate this exact project:

1.  **Create a Google Cloud Platform (GCP) Account**: If you don't have one already, you need to create a Google Cloud Platform account at <https://cloud.google.com/>. You'll need a Google account to sign up. (**Note that:** Google may require you to set up billing information to use their APIs, even if you're using them within the free tier. Follow the instructions provided to set up billing if prompted)

2.  **Create a New Project**: Once you're logged in to your GCP account, navigate to the Google Cloud Console. Then, select an existing project or create a new one and name it. Projects provide a way to organize and manage resources, and **each API usage is associated with a project**.

3.  **Enable the API options:** Once in your project, in the sidebar menu, go to "APIs & Services" \> "Library". Search for "Maps JavaScript API" and enable it. Inside, you will also have to enable "Places ID" and "Geocoding API".

4.  **Get an API Key**: After enabling these options, go to "APIs & Services" \> "Credentials". Click on "Create credentials" and select "API key". Copy and save the generated API key. (**Note that**: this is your personal key to access the Google API services).

5.  **Go back to Rstudio:** In Rstudio, create a *Text file* and write down: **apiKey = YOUR API KEY.** Then, save this file in your working directory as **.env** and read the following lines:

```{r, eval=FALSE}
dotenv::load_dot_env()
apiKey <- Sys.getenv("apiKey")
```

Now we're all setup! You should be able to make requests to the API from now on:

### Google Place Details using the Place ID

To acquire specific place details using the Google Maps API, each place needs to be uniquely identified. To achieve this, we've developed three distinct functions. These functions facilitate obtaining the Unique Identifier (Place ID) by initially sending a request to the Google Maps API. Subsequently, each function manages detail requests for individual places within its scope.

1.  **Place ID Retrieval**: To access detailed information about a place, we require its unique identifier known as the Place ID. This identifier can be obtained via the Google Geocoding API by submitting a request with the name of the place along with our API key.

2.  **Place Detail Request**: Subsequently, using the acquired Place ID, we will send a request to the Google Places API to retrieve comprehensive details about the specified place. The response from this request will contain the specific information regarding the queried place.

### Place ID and rating

```{r, eval=FALSE}
club1 <- "La Reserva Club"

placeid_rating <- function(club1, apiKey) {
  
    # Define the URL of the API Google Geocoding
  url_geocoding <- "https://maps.googleapis.com/maps/api/geocode/json"

  # Define parameters for geocoding request
  params_geocoding <- list(
    address = club1,
    key = apiKey
    )

  # Make the geocoding request
  response_geocoding <- GET(url_geocoding, query = params_geocoding)

  # Verify if the request was successful 
  if (http_type(response_geocoding) == "application/json") {
    
    # Parse JSON response
    json_response_geocoding <- content(response_geocoding, as = "parsed")

    # Extract the Place ID of the first result if it is available.
    if (length(json_response_geocoding$results) > 0) {
      place_id <- json_response_geocoding$results[[1]]$place_id
      
      # Define the Google Places API URL
      url_places <- "https://maps.googleapis.com/maps/api/place/details/json"

      # Define the parameters for the rating request
      params_places <- list(
        place_id = place_id,
        key = apiKey,
        fields = "rating"
      )

      #Making the request for the rating
      response_places <- GET(url_places, query = params_places)

      #  Verify if the request was successful 
      if (http_type(response_places) == "application/json") {
        # Parse JSON response
        json_response_places <- content(response_places, as = "parsed")

        # Return the rating of the place if available.
        if (!is.null(json_response_places$result$rating)) {
          place_rating <- json_response_places$result$rating
          return(place_rating)
        }
      }
    }
  }
  
  # If rating could not be obtained, return NA
  return(NA)
}

placeid_rating(club1, apiKey)
```

### Place ID and nº of reviews

```{r, eval=FALSE}
placeid_review <- function(club1, apiKey) {
  
  url_geocoding <- "https://maps.googleapis.com/maps/api/geocode/json"

  params_geocoding <- list(
    address = club1,
    key = apiKey
  )

  response_geocoding <- GET(url_geocoding, query = params_geocoding)

  if (http_type(response_geocoding) == "application/json") {
    json_response_geocoding <- content(response_geocoding, as = "parsed")

    if (length(json_response_geocoding$results) > 0) {
      place_id <- json_response_geocoding$results[[1]]$place_id
      
      url_places <- "https://maps.googleapis.com/maps/api/place/details/json"

      params_places <- list(
        place_id = place_id,
        key = apiKey,
        fields = "user_ratings_total"
      )

      response_places <- GET(url_places, query = params_places)

      if (http_type(response_places) == "application/json") {
        json_response_places <- content(response_places, as = "parsed")

        if (!is.null(json_response_places$result$user_ratings_total)) {
          place_review <- json_response_places$result$user_ratings_total
          return(place_review)
        }
      }
    }
  }
  
  return(NA)
}

placeid_review(club1, apiKey)
```

### Place ID and type

```{r, eval=FALSE}
placeid_type <- function(club1, apiKey) {
  
  url_geocoding <- "https://maps.googleapis.com/maps/api/geocode/json"

  params_geocoding <- list(
    address = club1,
    key = apiKey
  )

  response_geocoding <- GET(url_geocoding, query = params_geocoding)

  if (http_type(response_geocoding) == "application/json") {
    json_response_geocoding <- content(response_geocoding, as = "parsed")

    if (length(json_response_geocoding$results) > 0) {
      place_id <- json_response_geocoding$results[[1]]$place_id
      
      url_places <- "https://maps.googleapis.com/maps/api/place/details/json"

      params_places <- list(
        place_id = place_id,
        key = apiKey,
        fields = "type"
      )

      response_places <- GET(url_places, query = params_places)

      if (http_type(response_places) == "application/json") {
        json_response_places <- content(response_places, as = "parsed")

        if (!is.null(json_response_places$result$type[1])) {
          place_review <- json_response_places$result$type[1]
          return(place_review)
        }
      }
    }
  }
  
  # Si no se pudo obtener el rating, devolver NA
  return(NA)
}

placeid_type(club1, apiKey)
```

### Looping: creating the new variables

In this section, we apply our functions on the "place" column of our dataframe to create three different variables that will define the rating, the nº of reviews, and the type of place, respectively for each club. These variables will then be added in our main dataframe to perform the final visualizations.

**Rating variable**

```{r, eval=FALSE}
# Create a vector to save the ratings
ratings <- numeric(length(discotecas$place)) 

# Iterate on each place name and get its rating
for (i in seq_along(discotecas$place)) { 
  ratings[i] <- placeid_rating(discotecas$place[i], apiKey)
}

(as_tibble(ratings))

# Add the variable to the main dataframe
discotecas <- discotecas %>%
  mutate(rating = ratings)
discotecas$rating <- as.numeric(discotecas$rating)
```

**Number of reviews variable**

```{r, eval=FALSE}
reviews <- numeric(length(discotecas$place)) 

for (i in seq_along(discotecas$place)) { 
  reviews[i] <- placeid_review(discotecas$place[i], apiKey)
}

(as_tibble(reviews))

discotecas <- discotecas %>%
  mutate(numreview = reviews)
discotecas$numreview <- as.numeric(discotecas$numreview)
```

**Type of place variable**

```{r, eval=FALSE}
types <- character(length(discotecas$place)) 

for (i in seq_along(discotecas$place)) { 
  types[i] <- placeid_type(discotecas$place[i], apiKey)
}

discotecas$types <- types
discotecas$types <- sapply(discotecas$types, function(x) paste(unlist(x), collapse = ", "))
```

## Mapping clubs

```{r}
discotecas <- read_excel("discotecas.xlsx")
```

As noted before, the ultimate goal of this part is to visualize our variables in a map. For example, what if you want to visualize the highest ranked clubs based on the number of reviews? In the following plot, the intensity of the colors defines whether the club has a lower (light color) or a higher (dark color) rating, whereas the size of the point indicates the number of reviews in Google Maps.

### Rating and number of reviews, by club

```{r}
# Coordinates for Madrid
madrid_coords <- c(lat = 40.4168, lng = -3.7038)

# Define color palette based on  'rating' column
pal <- colorNumeric(palette = "Reds", domain = discotecas$rating)

# Initiate map with Leaflet
leaflet() |> 
  setView(lng = madrid_coords["lng"], 
          lat = madrid_coords["lat"],  
          zoom = 12) |> 
  addTiles() |> 
  addCircles(data = discotecas,  
             lng = ~lon, 
             lat = ~lat, 
             color = ~pal(rating), popup = ~place,   radius = ~sqrt(numreview)*2.5)|> addLegend(pal = pal, values = discotecas$rating, position = "bottomright", title = "Rating")
```

### Average price, by club

Similarly, we can visualize the average price in the following plot, by club.

```{r}
#Setting NA's as 0 
discotecas$avg_price[is.na(discotecas$avg_price)] <- 0
discotecas$avg_price <- as.numeric(discotecas$avg_price)
pal <- colorNumeric(palette = "Reds", domain = discotecas$avg_price)

leaflet() |> 
  setView(lng = madrid_coords["lng"], 
          lat = madrid_coords["lat"],  
          zoom = 12) |> 
  addTiles() |> 
  addCircles(data = discotecas,  
             lng = ~lon, 
             lat = ~lat, 
             color = ~pal(avg_price), popup = ~place, 
             radius = ~sqrt(avg_price)*20) |> 
               
  addLegend(pal = pal, values = discotecas$avg_price,
                         position = "bottomright", title = "Price Average") 
```

## Making a bar chart

Of the number of events each club has this month (for our subset of data)

```{r}
# Create a data frame with the count of events for each club_name
event_counts <- discotecas |> 
  group_by(club_name) |> 
  summarise(events = n_distinct(event_name)) |> 
  group_by(events) |> 
  summarise(num_clubs = n(), club_names = paste(club_name, collapse = ", ")) |> 
  arrange(desc(events))

event_counts$club_names <- str_wrap(event_counts$club_names, width = 20) 

label_data <- event_counts |> 
  mutate(label = ifelse(num_clubs > 1, paste(events, "(", num_clubs, " clubs)", sep = ""), as.character(events)))

```

```{r}
ggplot(event_counts, aes(x = reorder(club_names, -events), 
                         y = events)) +
  geom_bar(stat = "identity", fill = "cyan4") +
  geom_text(data = label_data,
            aes(label = label), vjust = -0.5, size = 3) +
  labs(title = "Number of Events per Club",
       x = "Club Name",
       y = "Number of Events") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 20))
```

## Weekday events

```{r}
weekday_events <- discotecas |> 
  filter(str_detect(full_date, "Lun|Mar\\.|Mié\\.|Jue\\."))

weekday_event_counts <- weekday_events |> 
  group_by(club_name) |> 
  summarise(weekday_event_count = n())
```

```{r}
ggplotly(
  ggplot(weekday_event_counts, aes(x = reorder(club_name, -weekday_event_count), y = weekday_event_count, text = paste("Weekday Event Count: ", weekday_event_count))) +
    geom_bar(stat = "identity", fill = "deeppink3") +
    labs(title = "Number of Weekday Events per Club",
         x = "Club Name",
         y = "Number of Weekday Events") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          plot.title = element_text(hjust = 0.5, face = "bold", size = 20)),
  tooltip = "text"
)
```

## Distribution of prices

```{r}
ggplotly(
  ggplot(discotecas, aes(x = entry_price, text = paste("Number of events: ", ..count..))) +
    geom_histogram(binwidth = 5, fill = "cyan4", color = "black") +
    labs(title = "Distribution of Entry Prices",
         x = "Entry Price",
         y = "Frequency") +
    theme_minimal() +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "transparent"),
          plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
          axis.title = element_text(size = 14),
          axis.text = element_text(size = 12))
)
```

## Final map with filters

Let's correct the date format first.

```{r, eval=FALSE}

discotecas$date <- as.character(discotecas$date)
discotecas$date <- as.Date(discotecas$date, format = "%Y-%m-%d")
```

```{r, eval=FALSE}
#There cannot be NAs in the variables for the creation of this map
discotecas$rating[is.na(discotecas$rating)] <- 0

```

```{r, eval=FALSE}

# Define UI for the Shiny app
ui <- fluidPage(
  
  # App title
  titlePanel("Interactive Map with Filters"),
  
  # Sidebar layout with input and output definitions
  sidebarLayout(
    
    # Sidebar panel for inputs
    sidebarPanel(
      
      # Slider for dress_code
      selectInput("dress_code", "Select Dress Code:",
                  choices = c("All", unique(discotecas$dress_code))),
      
      # Slider for district
      selectInput("district_name", "Select District:",
                  choices = c("All", unique(discotecas$district_name))),
      
      # Slider for date
      dateInput("date", "Select Date:", value = unique(discotecas$date)),
      
      # Slider for start_time
      sliderInput("start_time", "Select Start Time (24-hour format):",
                  min = 0, max = 24, value = c(0, 24)),
      
    
      # Checkbox for free
      radioButtons("free", "Free Entry:",
             choices = c("TRUE", "FALSE"),
             selected = "FALSE"),

      # Slider for entry_price
      sliderInput("entry_price", "Select Entry Price:",
                  min = min(discotecas$entry_price), 
                  max = max(discotecas$entry_price), 
                  value = c(min(discotecas$entry_price), max(discotecas$entry_price))), 
      
     # Slider for rating
      sliderInput("rating", "Select Rating:",
                  min = min(discotecas$rating), 
                  max = max(discotecas$rating), 
                  value = c(min(discotecas$rating), max(discotecas$rating))),
      
      # Slider for types
      selectInput("types", "Select Type of event:",
                  choices = c("All", unique(discotecas$types)))
    ),
    
    # Main panel for displaying the leaflet map
    mainPanel(
      leafletOutput("map", height = "720px")
    )
  )
)

# Define server logic
server <- function(input, output) {
  
  # Reactive expression to filter data based on inputs
  filtered_data <- reactive({
    filtered <- discotecas
    
    # Filter by dress_code if it's not "All"
    if (input$dress_code != "All") {
      filtered <- filtered |>  filter(dress_code == input$dress_code)
    }
    
    # Filter by district_name if it's not "All"
    if (input$district_name != "All") {
      filtered <- filtered |>  filter(district_name == input$district_name)
    }
    
    # Filter by date if it's not NULL
    if (!is.null(input$date)) {
      filtered <- filtered |>  filter(date == input$date)
    }
    
    # Filter by start_time
    filtered <- filtered |>  filter(as.numeric(substr(start_time, 1, 2)) >= input$start_time[1] &
                                      as.numeric(substr(start_time, 1, 2)) <= input$start_time[2])
    
    # Filter by free
    filtered <- filtered |> filter(free == input$free)
    
    # Filter by entry_price
    filtered <- filtered |> filter(entry_price >= input$entry_price[1] &
                                      entry_price <= input$entry_price[2])
    
    # Filter by rating
    filtered <- filtered |> filter(rating >= input$rating[1] &
                                     rating <= input$rating[2])
    
    # Filter by types
    if (input$types != "All") {
      filtered <- filtered |> filter(types == input$types)
    }
    
    return(filtered)
  })
  
  # Render leaflet map
  output$map <- renderLeaflet({
    leaflet() |> 
      addTiles() |> 
      addMarkers(data = filtered_data(),
                 ~lon, ~lat,
                 popup = ~paste("Club Name: ", club_name,
                                "<br>Date: ", date,
                                "<br>Event: ", event_name,
                                "<br>Start Time: ", start_time,
                                "<br>End Time: ", end_time,
                                "<br>Address: ", address))
  })
}

# Run the application
shinyApp(ui = ui, server = server)

```
